# -*- coding: utf-8 -*-
"""gan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FgWK_snWsNTLOVp0kuaUh00xWgdpjKjb
"""

import cv2
from PIL import Image
from keras.models import Sequential,load_model
from keras.layers import Flatten,Dense,Conv2D,Dropout,MaxPool2D,BatchNormalization,Reshape,UpSampling2D
from keras.optimizers import SGD
import numpy as np
import glob
from keras.utils import to_categorical

gen=Sequential()
gen.add(Dense(input_dim=100,activation='tanh',output_dim=1024))
gen.add(Dense(128*7*7,activation='tanh'))
gen.add(BatchNormalization())
gen.add(Reshape((7, 7, 128), input_shape=(128*7*7,)))
gen.add(UpSampling2D(size=(2, 2)))
gen.add(Conv2D(64, (5, 5), padding='same',activation='tanh'))
gen.add(UpSampling2D(size=(2, 2)))
gen.add(Conv2D(1, (5, 5), padding='same',activation='sigmoid'))
gen.summary()

d = Sequential()
d.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',
 activation ='relu', input_shape = (28,28,1)))
d.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same',
 activation ='relu'))
d.add(MaxPool2D(pool_size=(2,2)))
d.add(Dropout(0.25))
d.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',
 activation ='relu'))
d.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',
 activation ='relu'))
d.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))
d.add(Dropout(0.25))
d.add(Flatten())
d.add(Dense(256, activation = "relu"))
d.add(Dropout(0.5))
d.add(Dense(2, activation = "softmax"))
d.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
d.summary()

req=Sequential()
gen.trainable=True
req.add(gen)
d.trainable=False
req.add(d)
req.summary()
req.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

from keras.datasets import mnist
(X_train, y_train), (X_test, y_test) = mnist.load_data()
X_train=X_train.reshape(60000, 28, 28,1)
epochs=1
b=10000
for i in range(epochs):
  for pn in range(int(X_train.shape[0]/b)):
    k=list()
    k1=list()
    r=list()
    r1=list()
    for m in range(b):
      a=(b*pn)+m
      k.append(X_train[a]/255.0)
      k1.append(1)
      noise = np.random.uniform(-1, 1, (1,100))
      gh=gen.predict(noise)
      gh=gh.reshape(28,28,1)
      k.append(gh)
      k1.append(0)
      noise=noise.reshape(100)
      r.append(noise)
      r1.append(1)
    k=np.array(k)
    k1=np.array(k1)
    r=np.array(r)
    r1=np.array(r1)
    t=to_categorical(k1,2)
    d.trainable=True
    d.fit(k,t,shuffle=True)
    t=to_categorical(r1,2)
    d.trainable=False
    req.fit(r,t,shuffle=True)

def ans(n):
  n=np.expand_dims(n,axis=-1)
  n=n.reshape(1,100)
  g=model.predict(n)
  f=d.predict(g)
  f1=np.argmax(f)
  if f1==10:
    f[10]=0
    f1=np.argmax(f)
  g=to_categorical(f1,11)
  g=g.reshape(1,11)
  return g
'''def ans(n):
  n=np.expand_dims(n,axis=-1)
  n=n.reshape(1,100)
  g=model.predict(n)
  f=d.predict(g)
  g=[1,0]
  g=np.array(g)
  g=g.reshape(1,2)
  return g'''

for i in range(5000):
  noise = np.random.uniform(-1, 1, (1, 100))
  req.fit(noise,ans(noise),epochs=4)

noise = np.random.uniform(-1,1, (1, 100))
k=gen.predict(noise)
k=k*255.0
k=k.reshape(28,28)
import matplotlib.pyplot as plt
plt.imshow(k)
k=k.reshape(1,28,28,1)
d.predict(k/255.0)
#model.save('gen.h5')

l=k.reshape(784)
for i in range(784):
  if l[i]>127:
    l[i]=255
  else:
    l[i]=0
l=l.reshape(28,28)
plt.imshow(l)